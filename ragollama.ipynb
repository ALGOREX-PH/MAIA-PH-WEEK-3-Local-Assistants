{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning\n",
    "\n",
    "This notebook is designed to be read with a dark background. \n",
    "\n",
    "If you program with a white background, just know that you're a complete psychopath and a danger to society."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"https://www.maia.ph/logomaia.svg\" width=\"60\"/> Building a Local RAG System with Ollama and ChromaDB\n",
    "\n",
    "<div style=\"text-align: center; background-color: #f5f5f5; padding: 15px; border-radius: 8px; margin-bottom: 25px;\">\n",
    "  <img src=\"https://www.maia.ph/logomaia.svg\" width=\"120\" alt=\"MAIA Academy Logo\"/>\n",
    "  <h3 style=\"color: #000000; margin: 10px 0;\">Professional Data and Artificial Intelligence Education</h3>\n",
    "  <p style=\"color: #000000; margin-bottom: 15px;\">Join our thriving community of 500+ successful alumni across Europe and Asia</p>\n",
    "  <div style=\"margin-top: 10px;\">\n",
    "    <a href=\"https://www.maia.ph\" style=\"text-decoration: none; color: #000000; margin: 0 10px;\"><strong>Website:</strong> www.maia.ph</a> | \n",
    "    <a href=\"https://www.facebook.com/maiaedtech\" style=\"text-decoration: none; color: #000000; margin: 0 10px;\"><strong>Facebook:</strong> @maiaedtech</a> | \n",
    "    <a href=\"mailto:info@maia.ph\" style=\"text-decoration: none; color: #000000; margin: 0 10px;\"><strong>Email:</strong> info@maia.ph</a>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #f9f7ff; border-left: 6px solid #6d28d9; padding: 15px; margin: 20px 0; border-radius: 5px;\">\n",
    "<h3 style=\"color: #000000; margin-top: 0;\">üåü Welcome to the AI Frontier!</h3>\n",
    "<p style=\"color: #000000;\">Imagine having a brilliant research assistant who has read all your documents, remembers every detail, and can answer any question about them in seconds. That's exactly what we're building today!</p>\n",
    "</div>\n",
    "\n",
    "## üß† What Is RAG and Why Should You Care?\n",
    "\n",
    "**RAG (Retrieval Augmented Generation)** is one of the most powerful techniques in modern AI applications. Let's break it down:\n",
    "\n",
    "| Component | What It Does | Why It Matters |\n",
    "|-----------|--------------|----------------|\n",
    "| **Retrieval** | Finds relevant information from your documents | Ensures answers come from *your* data, not just the AI's training |\n",
    "| **Augmentation** | Enhances the AI's knowledge with this specific information | Makes responses accurate and up-to-date |\n",
    "| **Generation** | Creates human-like responses using the retrieved information | Delivers insights in natural, easy-to-understand language |\n",
    "\n",
    "<div style=\"background-color: #effaf5; border: 1px solid #0d9488; padding: 15px; margin: 20px 0; border-radius: 5px;\">\n",
    "<h4 style=\"color: #000000; margin-top: 0;\">üí° Real-World Analogy</h4>\n",
    "<p style=\"color: #000000;\">Think of RAG as the difference between:</p>\n",
    "<ul style=\"color: #000000;\">\n",
    "<li><strong>A general knowledge expert</strong> who studied years ago (standard LLM)</li>\n",
    "<li><strong>A specialist with your documents open</strong> in front of them, referencing exact paragraphs as they answer your questions (RAG system)</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "## üõ†Ô∏è Our Exciting Toolkit\n",
    "\n",
    "We'll be using several cutting-edge tools to build our RAG system:\n",
    "\n",
    "| Tool | What It Is | Why It's Amazing |\n",
    "|------|------------|------------------|\n",
    "| **Ollama** | An open-source platform that runs AI models locally on your computer | Privacy (your data never leaves your machine), no API costs, and complete control |\n",
    "| **ChromaDB** | A specialized database for storing and searching \"vector embeddings\" | Lightning-fast semantic search that understands meaning, not just keywords |\n",
    "| **LangChain** | A framework that connects AI components together like building blocks | Makes complex AI workflows simple and customizable |\n",
    "| **Gradio** | A tool for creating web interfaces for AI models | Turns your code into a professional-looking application in minutes |\n",
    "\n",
    "## üéØ What We'll Build Together\n",
    "\n",
    "By the end of this tutorial, you'll have created:\n",
    "\n",
    "```\n",
    "üìÑ Documents ‚Üí üî™ Chunker ‚Üí üßÆ Vector DB ‚Üí üîç Retriever ‚Üí ü§ñ LLM ‚Üí üí¨ Answer\n",
    "```\n",
    "\n",
    "A complete RAG system that can:\n",
    "\n",
    "1. **Process PDF documents** of your choice\n",
    "2. **Break them into smart chunks** that preserve meaning\n",
    "3. **Transform text into vectors** that capture semantic meaning\n",
    "4. **Store everything efficiently** for lightning-fast retrieval\n",
    "5. **Find the most relevant information** for any question\n",
    "6. **Generate accurate, helpful responses** with proper citations\n",
    "\n",
    "<div style=\"background-color: #ffe4e6; border-left: 6px solid #be123c; padding: 15px; margin: 20px 0; border-radius: 5px;\">\n",
    "<h3 style=\"color: #000000; margin-top: 0;\">üî• Why This Matters For Your Career</h3>\n",
    "<p style=\"color: #000000;\">RAG systems are at the forefront of practical AI applications. At MAIA Academy, we've seen how companies are rapidly adopting this technology to:</p>\n",
    "<ul style=\"color: #000000;\">\n",
    "<li>Build intelligent document assistants</li>\n",
    "<li>Create knowledge bases that actually answer questions</li>\n",
    "<li>Develop customer support systems that handle complex queries</li>\n",
    "<li>Implement research tools that synthesize information from multiple sources</li>\n",
    "</ul>\n",
    "<p style=\"color: #000000;\">The skills you'll learn today are directly transferable to real-world AI projects and align perfectly with our <strong>Foundations of AI Development</strong> and <strong>Deep Learning & LLMs</strong> modules!</p>\n",
    "</div>\n",
    "\n",
    "## üöÄ Let's Begin Our Journey!\n",
    "\n",
    "We'll start by understanding the core concepts, then move to implementation, and finally explore how to optimize your system for the best performance.\n",
    "\n",
    "<div style=\"text-align: center; margin: 30px 0; background-color: #f5f5f5; padding: 20px; border-radius: 10px;\">\n",
    "<img src=\"https://www.maia.ph/logomaia.svg\" width=\"120\" alt=\"MAIA Academy Logo\" style=\"margin-bottom: 15px;\"/>\n",
    "<h3 style=\"color: #000000;\">Professional Data and Artificial Intelligence Education</h3>\n",
    "<p style=\"color: #000000; font-size: 1.1em;\">Part of MAIA Academy's comprehensive AI Engineering curriculum</p>\n",
    "<p style=\"color: #000000;\">Ready to build the future of AI-powered knowledge systems? Let's dive in! üëá</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How Does This System Work?\n",
    "\n",
    "<div style=\"background-color: #f5f5f5; padding: 20px; border-radius: 8px; margin-bottom: 20px;\">\n",
    "  <h3 style=\"color: #000000; margin-top: 0;\">The RAG System Workflow</h3>\n",
    "  <p style=\"color: #000000;\">Picture this: you've got a pile of books (or PDFs), and you want to ask a super-smart friend some questions. Here's how our RAG system does it:</p>\n",
    "</div>\n",
    "\n",
    "<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0;\">\n",
    "  <tr style=\"background-color: #f9f7ff;\">\n",
    "    <td style=\"padding: 15px; border: 1px solid #ddd; width: 60px; text-align: center;\"><span style=\"font-size: 1.5em;\">1Ô∏è‚É£</span></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #ddd;\"><strong>Load the Books</strong><br><span style=\"color: #000000;\">We grab the PDFs and chop them into small pieces (chunks) that preserve meaning.</span></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 15px; border: 1px solid #ddd; width: 60px; text-align: center;\"><span style=\"font-size: 1.5em;\">2Ô∏è‚É£</span></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #ddd;\"><strong>Store the Pieces</strong><br><span style=\"color:rgb(255, 255, 255);\">We turn those pieces into a special format (vectors) and store them in ChromaDB.</span></td>\n",
    "  </tr>\n",
    "  <tr style=\"background-color: #f9f7ff;\">\n",
    "    <td style=\"padding: 15px; border: 1px solid #ddd; width: 60px; text-align: center;\"><span style=\"font-size: 1.5em;\">3Ô∏è‚É£</span></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #ddd;\"><strong>Ask Questions</strong><br><span style=\"color: #000000;\">You ask something, and the system hunts for the best matching pieces using semantic search.</span></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 15px; border: 1px solid #ddd; width: 60px; text-align: center;\"><span style=\"font-size: 1.5em;\">4Ô∏è‚É£</span></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #ddd;\"><strong>Get Answers</strong><br><span style=\"color:rgb(255, 255, 255);\">The AI (Ollama) uses those pieces to give you a clear, custom answer with proper citations.</span></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<div style=\"background-color: #effaf5; border: 1px solid #ddd; padding: 15px; border-radius: 8px; margin: 20px 0;\">\n",
    "  <p style=\"color: #000000; margin: 0;\"><strong>üîç Why This Matters:</strong> It's like having a research assistant who reads lightning-fast and always finds the exact page you need, but who can also synthesize and explain the information in a way that makes sense for your specific question.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center; margin: 30px 0 20px 0;\">\n",
    "  <p style=\"color:rgb(255, 255, 255); font-size: 1.1em; font-weight: bold;\">Let's set up our tools and get going!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (0.3.19)\n",
      "Collecting langchain_ollama\n",
      "  Downloading langchain_ollama-0.2.3-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting gradio\n",
      "  Downloading gradio-5.20.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (0.3.40)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (2.2.1)\n",
      "Collecting ollama<1,>=0.4.4 (from langchain_ollama)\n",
      "  Downloading ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (4.8.0)\n",
      "Collecting audioop-lts<1.0 (from gradio)\n",
      "  Downloading audioop_lts-0.2.1-cp313-abi3-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.7.2 (from gradio)\n",
      "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.28.1)\n",
      "Collecting huggingface-hub>=0.28.1 (from gradio)\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (3.1.5)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Downloading MarkupSafe-2.1.5.tar.gz (19 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (3.10.15)\n",
      "Requirement already satisfied: packaging in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (11.1.0)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.9.10-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fsspec (from gradio-client==1.7.2->gradio)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.7.2->gradio)\n",
      "  Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.19.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.21.0-cp313-cp313-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from chromadb) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from chromadb) (1.71.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp313-cp313-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Collecting filelock (from huggingface-hub>=0.28.1->gradio)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: protobuf in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.1)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading wrapt-1.17.2-cp313-cp313-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp313-cp313-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.0.4-cp313-cp313-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\danielle\\appdata\\roaming\\python\\python313\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Downloading langchain_ollama-0.2.3-py3-none-any.whl (19 kB)\n",
      "Downloading gradio-5.20.1-py3-none-any.whl (62.3 MB)\n",
      "   ---------------------------------------- 0.0/62.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 2.6/62.3 MB 12.8 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 6.3/62.3 MB 15.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 10.5/62.3 MB 16.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 14.7/62.3 MB 17.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 19.4/62.3 MB 18.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 23.9/62.3 MB 18.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 28.0/62.3 MB 18.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 32.5/62.3 MB 19.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 36.7/62.3 MB 19.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 40.9/62.3 MB 19.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 45.4/62.3 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 49.5/62.3 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 51.9/62.3 MB 18.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 55.6/62.3 MB 18.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 60.3/62.3 MB 18.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 62.3/62.3 MB 18.3 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
      "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
      "   ---------------------------------------- 0.0/611.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 611.1/611.1 kB 14.3 MB/s eta 0:00:00\n",
      "Downloading pypdf-5.3.1-py3-none-any.whl (302 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading audioop_lts-0.2.1-cp313-abi3-win_amd64.whl (30 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 14.6 MB/s eta 0:00:00\n",
      "Downloading mmh3-5.1.0-cp313-cp313-win_amd64.whl (41 kB)\n",
      "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\n",
      "Downloading onnxruntime-1.21.0-cp313-cp313-win_amd64.whl (11.8 MB)\n",
      "   ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 3.9/11.8 MB 19.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.1/11.8 MB 20.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.8 MB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.8/11.8 MB 17.8 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.31.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.31.0-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl (31 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl (183 kB)\n",
      "Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl (7.3 kB)\n",
      "Downloading opentelemetry_sdk-1.31.0-py3-none-any.whl (118 kB)\n",
      "Downloading posthog-3.19.1-py2.py3-none-any.whl (77 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.9.10-py3-none-win_amd64.whl (11.4 MB)\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 3.9/11.4 MB 19.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.4/11.4 MB 19.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.4/11.4 MB 19.1 MB/s eta 0:00:00\n",
      "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 17.5 MB/s eta 0:00:00\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading httptools-0.6.4-cp313-cp313-win_amd64.whl (87 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading watchfiles-1.0.4-cp313-cp313-win_amd64.whl (285 kB)\n",
      "Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl (176 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading wrapt-1.17.2-cp313-cp313-win_amd64.whl (38 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: chroma-hnswlib, markupsafe, pypika\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml): started\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.6-cp313-cp313-win_amd64.whl size=155499 sha256=f986e9364177103ef0a857322b209970d3e3a509418e48125ca2537e59a03f8f\n",
      "  Stored in directory: c:\\users\\danielle\\appdata\\local\\pip\\cache\\wheels\\e4\\de\\05\\47d2e8cd71d86b683765286c3308516ddcb7e8bf7db44fa69f\n",
      "  Building wheel for markupsafe (pyproject.toml): started\n",
      "  Building wheel for markupsafe (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for markupsafe: filename=markupsafe-2.1.5-cp313-cp313-win_amd64.whl size=17231 sha256=1714026399a8aef103c9616bb4cf7ac932460ec201c8781e6846b4e60b1417ce\n",
      "  Stored in directory: c:\\users\\danielle\\appdata\\local\\pip\\cache\\wheels\\c2\\0c\\c0\\d6d953ac80cacc2dd1d329d675c67d1e7775bad02a8faedef0\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53882 sha256=5b07643adf35a8dccf39540bc0e3af1576aabf83d365bdb39fea546eec69f80f\n",
      "  Stored in directory: c:\\users\\danielle\\appdata\\local\\pip\\cache\\wheels\\b4\\f8\\a5\\28e9c1524d320f4b8eefdce0e487b5c2e128dbf2ed1bb4a60b\n",
      "Successfully built chroma-hnswlib markupsafe pypika\n",
      "Installing collected packages: pypika, pydub, monotonic, flatbuffers, durationpy, wrapt, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, pyreadline3, pyproject_hooks, pypdf, opentelemetry-util-http, opentelemetry-proto, oauthlib, mmh3, markupsafe, importlib-resources, httptools, groovy, fsspec, filelock, ffmpy, chroma-hnswlib, bcrypt, backoff, audioop-lts, asgiref, aiofiles, watchfiles, uvicorn, starlette, requests-oauthlib, posthog, opentelemetry-exporter-otlp-proto-common, humanfriendly, huggingface-hub, deprecated, build, typer, tokenizers, safehttpx, opentelemetry-api, ollama, kubernetes, gradio-client, fastapi, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, gradio, opentelemetry-sdk, opentelemetry-instrumentation, langchain_ollama, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "Successfully installed aiofiles-23.2.1 asgiref-3.8.1 audioop-lts-0.2.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 deprecated-1.2.18 durationpy-0.9 fastapi-0.115.11 ffmpy-0.5.0 filelock-3.17.0 flatbuffers-25.2.10 fsspec-2025.3.0 gradio-5.20.1 gradio-client-1.7.2 groovy-0.1.2 httptools-0.6.4 huggingface-hub-0.29.3 humanfriendly-10.0 importlib-resources-6.5.2 kubernetes-32.0.1 langchain_ollama-0.2.3 markupsafe-2.1.5 mmh3-5.1.0 monotonic-1.6 oauthlib-3.2.2 ollama-0.4.7 onnxruntime-1.21.0 opentelemetry-api-1.31.0 opentelemetry-exporter-otlp-proto-common-1.31.0 opentelemetry-exporter-otlp-proto-grpc-1.31.0 opentelemetry-instrumentation-0.52b0 opentelemetry-instrumentation-asgi-0.52b0 opentelemetry-instrumentation-fastapi-0.52b0 opentelemetry-proto-1.31.0 opentelemetry-sdk-1.31.0 opentelemetry-semantic-conventions-0.52b0 opentelemetry-util-http-0.52b0 posthog-3.19.1 pydub-0.25.1 pypdf-5.3.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 python-multipart-0.0.20 requests-oauthlib-2.0.0 ruff-0.9.10 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.46.1 tokenizers-0.21.0 tomlkit-0.13.2 typer-0.15.2 uvicorn-0.34.0 watchfiles-1.0.4 websockets-15.0.1 wrapt-1.17.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "!pip install langchain langchain_ollama gradio chromadb pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "# Standard imports\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import tempfile\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# Gradio for web interface\n",
    "import gradio as gr\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting the Stage: Configuration\n",
    "\n",
    "<div style=\"background-color: #2d333b; padding: 20px; border-radius: 8px; margin-bottom: 20px; border-left: 6px solid #58a6ff;\">\n",
    "  <h3 style=\"color: #ffffff; margin-top: 0;\">System Configuration Parameters</h3>\n",
    "  <p style=\"color: #ffffff;\">Before we build our RAG system, we need to configure some important settings‚Äîlike tuning a new instrument before a performance. These parameters will determine how our system processes and interacts with documents.</p>\n",
    "</div>\n",
    "\n",
    "<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0; background-color: #22272e;\">\n",
    "  <tr>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56; width: 200px;\"><strong style=\"color: #58a6ff;\">PERSIST_DIRECTORY</strong></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56; color: #adbac7;\">Where we'll store our \"data safe\" (the vector database) on disk. This allows our system to remember what it learned even after restarting.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56;\"><strong style=\"color: #58a6ff;\">CHUNK_SIZE</strong></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56; color: #adbac7;\">How big each text piece will be (in characters). This affects how much context the AI has when answering questions.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56;\"><strong style=\"color: #58a6ff;\">CHUNK_OVERLAP</strong></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56; color: #adbac7;\">How much the pieces overlap to maintain context between chunks and ensure no information is lost at the boundaries.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56;\"><strong style=\"color: #58a6ff;\">PDF_URLS</strong></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56; color: #adbac7;\">The documents we'll use as our knowledge base (our \"reference library\"). These are the sources the system will learn from.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56;\"><strong style=\"color: #58a6ff;\">LLM_MODEL</strong></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56; color: #adbac7;\">The \"brain\" that processes the context and generates answers (like llama3 or other models available in Ollama).</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56;\"><strong style=\"color: #58a6ff;\">EMBEDDING_MODEL</strong></td>\n",
    "    <td style=\"padding: 15px; border: 1px solid #444c56; color: #adbac7;\">The \"translator\" that converts text into numerical vectors that capture meaning. Different models balance between speed and accuracy.</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<div style=\"background-color: #2d333b; border: 1px solid #444c56; padding: 20px; border-radius: 8px; margin: 20px 0;\">\n",
    "  <h3 style=\"color: #58a6ff; margin-top: 0;\">üí° What's This Chunk Stuff?</h3>\n",
    "  <p style=\"color: #adbac7;\">Think of cutting a big sandwich. If the pieces are huge, you get more filling but it's hard to bite. If they're tiny, you bite easy but might miss the full flavor. Overlap is like leaving a bit of the last bite on the next one so you don't lose track of the overall taste.</p>\n",
    "  \n",
    "  <div style=\"display: flex; justify-content: space-between; margin-top: 20px; text-align: center;\">\n",
    "    <div style=\"flex: 1; margin: 0 10px;\">\n",
    "      <p style=\"color: #58a6ff;\"><strong>Large Chunks (2000+)</strong></p>\n",
    "      <p style=\"color: #adbac7;\">‚úÖ More context<br>‚úÖ Better for complex topics<br>‚ùå Less precise retrieval<br>‚ùå Slower processing</p>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; margin: 0 10px;\">\n",
    "      <p style=\"color: #58a6ff;\"><strong>Medium Chunks (800-1200)</strong></p>\n",
    "      <p style=\"color: #adbac7;\">‚úÖ Balanced approach<br>‚úÖ Good for most cases<br>‚úÖ Reasonable speed<br>‚úÖ Decent precision</p>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; margin: 0 10px;\">\n",
    "      <p style=\"color: #58a6ff;\"><strong>Small Chunks (300-500)</strong></p>\n",
    "      <p style=\"color: #adbac7;\">‚úÖ Very precise retrieval<br>‚úÖ Fast processing<br>‚ùå Limited context<br>‚ùå May miss broader concepts</p>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center; background-color: #22272e; padding: 10px; border-radius: 5px; margin-top: 20px;\">\n",
    "  <p style=\"color: #ff7b72; font-weight: bold;\">‚ö†Ô∏è Warning</p>\n",
    "  <p style=\"color: #adbac7;\">This notebook is designed to be read with a dark background. If you program with a white background, just know that you're a complete psychopath and a danger to society.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "PDF_URLS = [ #here danielle we can being participaty alumns to search pdfs online and give us engagement in meeting (+3 retention stats up)\n",
    "    \"https://www.ine.es/daco/daco42/ecp/ecp0123.pdf\",\n",
    "    \"https://fundacionalternativas.org/wp-content/uploads/2023/10/PERSONAS_MIGRANTES_v02.pdf\"\n",
    "]\n",
    "LLM_MODEL = \"llama3.2:1b\"  # Using a small Llama model for faster responses\n",
    "EMBEDDING_MODEL = \"all-minilm\"  # Small, fast embedding model (22M parameters)\n",
    "TEMPERATURE = 0.1  # Lower temperature for more deterministic outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Heart of It: RAGSystem Class\n",
    "\n",
    "Now, let‚Äôs create the main ‚Äúrobot‚Äù that does all the work: the RAGSystem class. This robot gets ready with all the tools it needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSystem:\n",
    "    \"\"\"Main class for the RAG (Retrieval Augmented Generation) system\"\"\"\n",
    "    \n",
    "    def __init__(self, pdf_urls: List[str], persist_directory: str = PERSIST_DIRECTORY):\n",
    "        \"\"\"\n",
    "        Initialize the RAG system\n",
    "        \n",
    "        Args:\n",
    "            pdf_urls: List of URLs or local paths to PDFs\n",
    "            persist_directory: Directory to persist the vector database\n",
    "        \"\"\"\n",
    "        self.pdf_urls = pdf_urls\n",
    "        self.persist_directory = persist_directory\n",
    "        self.documents = []\n",
    "        self.vectorstore = None\n",
    "        self.llm = None\n",
    "        self.chain = None\n",
    "        \n",
    "        # Initialize the LLM with streaming capability\n",
    "        callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "        self.llm = ChatOllama(\n",
    "            model=LLM_MODEL,\n",
    "            temperature=TEMPERATURE,\n",
    "            callback_manager=callback_manager\n",
    "        )\n",
    "        \n",
    "        # Initialize embeddings\n",
    "        self.embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)\n",
    "        \n",
    "        logger.info(f\"Initialized RAG system with {len(pdf_urls)} PDFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building Our RAG System\n",
    "\n",
    "<div style=\"background-color: #2d333b; padding: 5px; border-radius: 4px; margin-bottom: 10px;\">\n",
    "  <h3 style=\"color: #58a6ff; margin: 10px;\">3.1 Loading and Chopping Documents</h3>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #22272e; padding: 15px; border-radius: 8px; border-left: 4px solid #7ee787; margin-bottom: 20px;\">\n",
    "  <p style=\"color: #adbac7;\">The first crucial step in our RAG pipeline is to read PDFs and slice them into manageable chunks. This process transforms raw documents into pieces our system can effectively process.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #2d333b; border: 1px solid #444c56; padding: 20px; border-radius: 8px; margin: 20px 0;\">\n",
    "  <h4 style=\"color: #7ee787; margin-top: 0;\">üìö Why Do We Chop?</h4>\n",
    "  \n",
    "  <p style=\"color: #adbac7;\">Imagine a huge cake: you can't eat it all at once, so you cut it into slices. Same with documents:</p>\n",
    "  \n",
    "  <ul style=\"color: #adbac7; margin-left: 20px;\">\n",
    "    <li><strong style=\"color: #d2a8ff;\">AI has a \"small tummy\"</strong> (a context window that limits how much text it can process at once)</li>\n",
    "    <li><strong style=\"color: #d2a8ff;\">Small chunks help find exact answers fast</strong> (better retrieval precision)</li>\n",
    "    <li><strong style=\"color: #d2a8ff;\">It makes the system quicker and less likely to choke</strong> (more efficient processing)</li>\n",
    "  </ul>\n",
    "  \n",
    "  <div style=\"margin-top: 25px; background-color: #22272e; padding: 15px; border-radius: 5px; border: 1px dashed #444c56;\">\n",
    "    <h5 style=\"color: #58a6ff; margin-top: 0;\">üîç Technical Insight: The Chunking Process</h5>\n",
    "    <p style=\"color: #adbac7;\">Our system uses a <code style=\"background-color: #2d333b; padding: 2px 5px; border-radius: 3px; color: #ff7b72;\">RecursiveCharacterTextSplitter</code> that intelligently divides text based on:</p>\n",
    "    <ul style=\"color: #adbac7;\">\n",
    "      <li>Natural boundaries (paragraphs, sentences)</li>\n",
    "      <li>Configured chunk size (how many characters per chunk)</li>\n",
    "      <li>Strategic overlap to maintain context between chunks</li>\n",
    "    </ul>\n",
    "    <p style=\"color: #adbac7;\">This ensures that each chunk contains coherent, meaningful information rather than arbitrary text divisions.</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; background-color: #22272e; border-radius: 8px; overflow: hidden; margin: 20px 0;\">\n",
    "  <div style=\"flex: 1; padding: 15px; border-right: 1px solid #444c56;\">\n",
    "    <p style=\"color: #58a6ff; font-weight: bold; margin-top: 0;\">Document Loading</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">üëâ Reading PDFs using PyPDFLoader</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">üëâ Extracting text and metadata</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">üëâ Handling multiple documents</p>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; padding: 15px; border-right: 1px solid #444c56;\">\n",
    "    <p style=\"color: #58a6ff; font-weight: bold; margin-top: 0;\">Document Chunking</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">üëâ Splitting into smaller pieces</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">üëâ Maintaining logical boundaries</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">üëâ Creating overlapping sections</p>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; padding: 15px;\">\n",
    "    <p style=\"color: #58a6ff; font-weight: bold; margin-top: 0;\">Result</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">üëâ Dozens or hundreds of chunks</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">üëâ Each ~1000 characters long</p>\n",
    "    <p style=\"color: #adbac7; margin-bottom: 0;\">üëâ Ready for embedding creation</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #2d333b; border-left: 4px solid #f97583; padding: 15px; border-radius: 5px; margin-top: 20px;\">\n",
    "  <p style=\"color: #adbac7; margin: 0;\"><strong style=\"color: #f97583;\">‚ö†Ô∏è Common Pitfall:</strong> Setting your chunk size too small (under 300 characters) or too large (over 2000 characters) can severely impact your system's performance. Start with ~1000 and adjust based on your specific documents and query needs.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(self) -> None:\n",
    "    \"\"\"Load and split PDF documents\"\"\"\n",
    "    logger.info(\"Loading and processing PDFs...\")\n",
    "    \n",
    "    # Text splitter for chunking documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    all_pages = []\n",
    "    for url in self.pdf_urls:\n",
    "        try:\n",
    "            loader = PyPDFLoader(url)\n",
    "            pages = loader.load()\n",
    "            logger.info(f\"Loaded {len(pages)} pages from {url}\")\n",
    "            all_pages.extend(pages)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading PDF from {url}: {e}\")\n",
    "    \n",
    "    # Split the documents into chunks\n",
    "    self.documents = text_splitter.split_documents(all_pages)\n",
    "    logger.info(f\"Created {len(self.documents)} document chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #2d333b; padding: 5px; border-radius: 4px; margin-bottom: 10px;\">\n",
    "  <h3 style=\"color: #58a6ff; margin: 10px;\">3.2 Storing in a Vector Database</h3>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #22272e; padding: 15px; border-radius: 8px; border-left: 4px solid #f0883e; margin-bottom: 20px;\">\n",
    "  <p style=\"color: #adbac7;\">After chunking our documents, we need to store them in a way that allows for intelligent searching. This is where vectors and ChromaDB come into play.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #2d333b; border: 1px solid #444c56; padding: 20px; border-radius: 8px; margin: 20px 0;\">\n",
    "  <h4 style=\"color: #f0883e; margin-top: 0;\">üßÆ What Are Vectors?</h4>\n",
    "  \n",
    "  <p style=\"color: #adbac7;\">Think of each chunk as a person, and we give it a unique \"fingerprint\" based on what it says. These fingerprints are actually lists of numbers that capture meaning.</p>\n",
    "  \n",
    "  <div style=\"display: flex; margin-top: 20px; background-color: #22272e; padding: 15px; border-radius: 8px;\">\n",
    "    <div style=\"flex: 1; padding-right: 15px;\">\n",
    "      <p style=\"color: #adbac7; font-style: italic; margin-top: 0;\">\"I like the sun\"</p>\n",
    "      <p style=\"color: #d2a8ff; font-family: monospace; font-size: 0.9em;\">[0.12, -0.33, 0.65, ...]</p>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; padding-left: 15px; border-left: 1px dashed #444c56;\">\n",
    "      <p style=\"color: #adbac7; font-style: italic; margin-top: 0;\">\"I love the heat\"</p>\n",
    "      <p style=\"color: #d2a8ff; font-family: monospace; font-size: 0.9em;\">[0.15, -0.28, 0.61, ...]</p>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <p style=\"color: #adbac7; margin-top: 20px;\">These sentences get similar vector \"fingerprints\" because they express similar concepts. This lets us search by <strong>meaning</strong>, not just exact words.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; background-color: #22272e; border-radius: 8px; overflow: hidden; margin: 20px 0; border: 1px solid #444c56;\">\n",
    "  <div style=\"flex: 1; padding: 15px; display: flex; flex-direction: column; align-items: center; text-align: center; border-right: 1px solid #444c56;\">\n",
    "    <div style=\"background-color: #2d333b; width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n",
    "      <span style=\"color: #58a6ff; font-weight: bold; font-size: 1.5em;\">1</span>\n",
    "    </div>\n",
    "    <p style=\"color: #f0883e; font-weight: bold; margin: 5px 0;\">Convert</p>\n",
    "    <p style=\"color: #adbac7; margin: 5px 0;\">Text ‚Üí Vector</p>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; padding: 15px; display: flex; flex-direction: column; align-items: center; text-align: center; border-right: 1px solid #444c56;\">\n",
    "    <div style=\"background-color: #2d333b; width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n",
    "      <span style=\"color: #58a6ff; font-weight: bold; font-size: 1.5em;\">2</span>\n",
    "    </div>\n",
    "    <p style=\"color: #f0883e; font-weight: bold; margin: 5px 0;\">Store</p>\n",
    "    <p style=\"color: #adbac7; margin: 5px 0;\">In ChromaDB</p>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; padding: 15px; display: flex; flex-direction: column; align-items: center; text-align: center;\">\n",
    "    <div style=\"background-color: #2d333b; width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n",
    "      <span style=\"color: #58a6ff; font-weight: bold; font-size: 1.5em;\">3</span>\n",
    "    </div>\n",
    "    <p style=\"color: #f0883e; font-weight: bold; margin: 5px 0;\">Retrieve</p>\n",
    "    <p style=\"color: #adbac7; margin: 5px 0;\">By Similarity</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #22272e; padding: 20px; border-radius: 8px; margin: 20px 0; border: 1px solid #444c56;\">\n",
    "  <h4 style=\"color: #58a6ff; margin-top: 0;\">In Plain English:</h4>\n",
    "  \n",
    "  <p style=\"color: #adbac7;\">1. <strong>We transform text into numbers</strong> using the embedding model (all-minilm)</p>\n",
    "  <p style=\"color: #adbac7;\">2. <strong>We store these numbers in ChromaDB</strong> along with the original text</p>\n",
    "  <p style=\"color: #adbac7;\">3. <strong>When you ask a question</strong>, we convert your question to a vector too</p>\n",
    "  <p style=\"color: #adbac7;\">4. <strong>ChromaDB finds chunks with similar vectors</strong> to your question</p>\n",
    "  <p style=\"color: #adbac7;\">5. <strong>These similar chunks</strong> likely contain the answer you need</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; background-color: #22272e; border-radius: 8px; margin: 20px 0;\">\n",
    "  <div style=\"flex: 1; padding: 20px;\">\n",
    "    <h5 style=\"color: #7ee787; margin-top: 0;\">üí° Why This Is Cool</h5>\n",
    "    <ul style=\"color: #adbac7; list-style-type: none; padding-left: 0;\">\n",
    "      <li style=\"margin-bottom: 8px;\">‚úÖ <strong>Finds similar concepts</strong>, even with different words</li>\n",
    "      <li style=\"margin-bottom: 8px;\">‚úÖ <strong>Lightning-fast search</strong> of large document collections</li>\n",
    "      <li style=\"margin-bottom: 8px;\">‚úÖ <strong>Works across languages</strong> (Spanish \"sol\" ‚âà English \"sun\")</li>\n",
    "      <li>‚úÖ <strong>More accurate</strong> than keyword searching</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #2d333b; border-left: 4px solid #d2a8ff; padding: 15px; border-radius: 5px; margin-top: 20px;\">\n",
    "  <p style=\"color: #adbac7; margin: 0;\"><strong style=\"color: #d2a8ff;\">üöÄ Pro Tip:</strong> Think of it like searching a music library - you find songs that \"sound similar\" to the one you like, not just songs with the exact same title.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(self) -> None:\n",
    "    \"\"\"Create a fresh vector database\"\"\"\n",
    "    # Remove any existing database\n",
    "    if os.path.exists(self.persist_directory):\n",
    "        import shutil\n",
    "        logger.info(f\"Removing existing vectorstore at {self.persist_directory}\")\n",
    "        shutil.rmtree(self.persist_directory, ignore_errors=True)\n",
    "    \n",
    "    # Create a new vectorstore\n",
    "    logger.info(\"Creating new vectorstore...\")\n",
    "    if not self.documents:\n",
    "        self.load_documents()\n",
    "    \n",
    "    # Create a temporary directory for the database\n",
    "    # This helps avoid permission issues on some systems\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    logger.info(f\"Using temporary directory for initial database creation: {temp_dir}\")\n",
    "    \n",
    "    try:\n",
    "        # First create in temp directory\n",
    "        self.vectorstore = Chroma.from_documents(\n",
    "            documents=self.documents,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=temp_dir\n",
    "        )\n",
    "        \n",
    "        # Now create the real directory\n",
    "        if not os.path.exists(self.persist_directory):\n",
    "            os.makedirs(self.persist_directory)\n",
    "            \n",
    "        # And create the final vectorstore\n",
    "        self.vectorstore = Chroma.from_documents(\n",
    "            documents=self.documents,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=self.persist_directory\n",
    "        )\n",
    "        self.vectorstore.persist()\n",
    "        \n",
    "        logger.info(f\"Vectorstore created successfully with {len(self.documents)} documents\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating vectorstore: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        # Clean up temp directory\n",
    "        if os.path.exists(temp_dir):\n",
    "            import shutil\n",
    "            shutil.rmtree(temp_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #2d333b; padding: 5px; border-radius: 4px; margin-bottom: 10px;\">\n",
    "  <h3 style=\"color: #58a6ff; margin: 10px;\">3.3 Building the RAG Chain</h3>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #22272e; padding: 15px; border-radius: 8px; border-left: 4px solid #79c0ff; margin-bottom: 20px;\">\n",
    "  <p style=\"color: #adbac7;\">Here's where our system turns into a \"detective.\" We connect all the components into a sequence that transforms questions into accurate answers.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #1c2128; padding: 20px; border-radius: 8px; margin: 20px 0; border: 1px solid #444c56;\">\n",
    "  <h4 style=\"color: #79c0ff; margin-top: 0; text-align: center; margin-bottom: 20px;\">The RAG Chain Components</h4>\n",
    "  \n",
    "  <!-- Retriever Component -->\n",
    "  <div style=\"background-color: #22272e; border-radius: 8px; padding: 15px; margin-bottom: 15px; border: 1px solid #444c56;\">\n",
    "    <div style=\"display: flex; align-items: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-right: 15px;\">\n",
    "        <span style=\"font-size: 1.5em;\">üîç</span>\n",
    "      </div>\n",
    "      <div>\n",
    "        <p style=\"color: #79c0ff; margin: 0; font-weight: bold;\">The Searcher (Retriever)</p>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"margin-top: 10px; padding-left: 65px;\">\n",
    "      <p style=\"color: #adbac7; margin: 0;\">Turns your question into a fingerprint and finds the closest matches in the database.</p>\n",
    "      <div style=\"background-color: #2d333b; padding: 8px; border-radius: 4px; margin-top: 10px;\">\n",
    "        <code style=\"color: #d2a8ff; font-size: 0.9em;\">retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})</code>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <!-- Prompt Template Component -->\n",
    "  <div style=\"background-color: #22272e; border-radius: 8px; padding: 15px; margin-bottom: 15px; border: 1px solid #444c56;\">\n",
    "    <div style=\"display: flex; align-items: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-right: 15px;\">\n",
    "        <span style=\"font-size: 1.5em;\">üìù</span>\n",
    "      </div>\n",
    "      <div>\n",
    "        <p style=\"color: #79c0ff; margin: 0; font-weight: bold;\">The Instructions (Prompt)</p>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"margin-top: 10px; padding-left: 65px;\">\n",
    "      <p style=\"color: #adbac7; margin: 0;\">Like a recipe: \"Be nice, use the chunks, cite your sources.\" This keeps answers helpful and trustworthy.</p>\n",
    "      <div style=\"background-color: #2d333b; padding: 8px; border-radius: 4px; margin-top: 10px;\">\n",
    "        <code style=\"color: #d2a8ff; font-size: 0.9em;\">prompt = PromptTemplate.from_template(template)</code>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <!-- LLM Component -->\n",
    "  <div style=\"background-color: #22272e; border-radius: 8px; padding: 15px; margin-bottom: 15px; border: 1px solid #444c56;\">\n",
    "    <div style=\"display: flex; align-items: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-right: 15px;\">\n",
    "        <span style=\"font-size: 1.5em;\">üß†</span>\n",
    "      </div>\n",
    "      <div>\n",
    "        <p style=\"color: #79c0ff; margin: 0; font-weight: bold;\">The AI (LLM)</p>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"margin-top: 10px; padding-left: 65px;\">\n",
    "      <p style=\"color: #adbac7; margin: 0;\">Writes the final response based on the instructions and retrieved chunks.</p>\n",
    "      <div style=\"background-color: #2d333b; padding: 8px; border-radius: 4px; margin-top: 10px;\">\n",
    "        <code style=\"color: #d2a8ff; font-size: 0.9em;\">llm = ChatOllama(model=\"llama3\", temperature=0.1)</code>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <!-- Output Parser Component -->\n",
    "  <div style=\"background-color: #22272e; border-radius: 8px; padding: 15px; margin-bottom: 0; border: 1px solid #444c56;\">\n",
    "    <div style=\"display: flex; align-items: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-right: 15px;\">\n",
    "        <span style=\"font-size: 1.5em;\">‚ú®</span>\n",
    "      </div>\n",
    "      <div>\n",
    "        <p style=\"color: #79c0ff; margin: 0; font-weight: bold;\">The Formatter (Parser)</p>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"margin-top: 10px; padding-left: 65px;\">\n",
    "      <p style=\"color: #adbac7; margin: 0;\">Makes the response neat and clear for the user to read.</p>\n",
    "      <div style=\"background-color: #2d333b; padding: 8px; border-radius: 4px; margin-top: 10px;\">\n",
    "        <code style=\"color: #d2a8ff; font-size: 0.9em;\">StrOutputParser()</code>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<!-- Flow diagram -->\n",
    "<div style=\"background-color: #22272e; padding: 20px; border-radius: 8px; margin: 20px 0;\">\n",
    "  <h4 style=\"color: #79c0ff; margin-top: 0; text-align: center;\">How It All Flows Together</h4>\n",
    "  \n",
    "  <div style=\"display: flex; justify-content: center; align-items: center; flex-wrap: wrap; margin: 20px 0;\">\n",
    "    <div style=\"text-align: center; background-color: #2d333b; padding: 15px; border-radius: 8px; margin: 5px;\">\n",
    "      <div style=\"font-size: 2em; margin-bottom: 5px;\">‚ùì</div>\n",
    "      <div style=\"color: #adbac7;\">Question</div>\n",
    "    </div>\n",
    "    <div style=\"font-size: 1.5em; margin: 0 10px; color: #adbac7;\">‚Üí</div>\n",
    "    <div style=\"text-align: center; background-color: #2d333b; padding: 15px; border-radius: 8px; margin: 5px;\">\n",
    "      <div style=\"font-size: 2em; margin-bottom: 5px;\">üîç</div>\n",
    "      <div style=\"color: #adbac7;\">Retriever</div>\n",
    "    </div>\n",
    "    <div style=\"font-size: 1.5em; margin: 0 10px; color: #adbac7;\">‚Üí</div>\n",
    "    <div style=\"text-align: center; background-color: #2d333b; padding: 15px; border-radius: 8px; margin: 5px;\">\n",
    "      <div style=\"font-size: 2em; margin-bottom: 5px;\">üìù</div>\n",
    "      <div style=\"color: #adbac7;\">Prompt</div>\n",
    "    </div>\n",
    "    <div style=\"font-size: 1.5em; margin: 0 10px; color: #adbac7;\">‚Üí</div>\n",
    "    <div style=\"text-align: center; background-color: #2d333b; padding: 15px; border-radius: 8px; margin: 5px;\">\n",
    "      <div style=\"font-size: 2em; margin-bottom: 5px;\">üß†</div>\n",
    "      <div style=\"color: #adbac7;\">LLM</div>\n",
    "    </div>\n",
    "    <div style=\"font-size: 1.5em; margin: 0 10px; color: #adbac7;\">‚Üí</div>\n",
    "    <div style=\"text-align: center; background-color: #2d333b; padding: 15px; border-radius: 8px; margin: 5px;\">\n",
    "      <div style=\"font-size: 2em; margin-bottom: 5px;\">‚ú®</div>\n",
    "      <div style=\"color: #adbac7;\">Parser</div>\n",
    "    </div>\n",
    "    <div style=\"font-size: 1.5em; margin: 0 10px; color: #adbac7;\">‚Üí</div>\n",
    "    <div style=\"text-align: center; background-color: #2d333b; padding: 15px; border-radius: 8px; margin: 5px;\">\n",
    "      <div style=\"font-size: 2em; margin-bottom: 5px;\">üí°</div>\n",
    "      <div style=\"color: #adbac7;\">Answer</div>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <div style=\"background-color: #1c2128; padding: 15px; border-radius: 8px; margin-top: 20px;\">\n",
    "    <p style=\"color: #adbac7; margin: 0; text-align: center;\">This entire chain is created with just a few lines of code:</p>\n",
    "    <div style=\"background-color: #2d333b; border-radius: 5px; padding: 15px; margin-top: 10px; font-family: monospace;\">\n",
    "      <pre style=\"color: #d2a8ff; margin: 0; overflow-x: auto; font-size: 0.9em;\">self.chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | self.llm\n",
    "    | StrOutputParser()\n",
    ")</pre>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #2d333b; border-left: 4px solid #58a6ff; padding: 15px; border-radius: 5px; margin-top: 20px;\">\n",
    "  <p style=\"color: #adbac7; margin: 0;\"><strong style=\"color: #adbac7;\">üí° Pro Tip:</strong> The key to a good RAG system is balance. A great prompt template with poor retrieval won't work well, and perfect retrieval with bad instructions will still give bad answers. All pieces need to work together!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_chain(self) -> None:\n",
    "    \"\"\"Set up the RAG chain for question answering\"\"\"\n",
    "    if not self.vectorstore:\n",
    "        self.create_vectorstore()\n",
    "    \n",
    "    # Create retriever with search parameters\n",
    "    retriever = self.vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5}  # Return top 5 most relevant chunks\n",
    "    )\n",
    "    \n",
    "    # Define the prompt template\n",
    "    template = \"\"\"\n",
    "    ### INSTRUCTIONS: \n",
    "    You are an AI assistant dedicated to answering questions in a polite and professional manner. You must provide a helpful response to the user.\n",
    "    \n",
    "    (1) Be attentive to details: read the question and context thoroughly before answering.\n",
    "    (2) Begin your response with a friendly tone and reiterate the question to ensure you understood it.\n",
    "    (3) If the context allows you to answer the question, write a detailed, helpful, and easy-to-understand response, with sources referenced in the text. IF NOT: if you cannot find the answer, respond with an explanation, starting with: \"I couldn't find the information in the documents I have access to.\"\n",
    "    (4) Below your response, please list all referenced sources (i.e., document sections that support your claims).\n",
    "    (5) Review your answer to ensure you answered the question, the response is helpful and professional, and it's formatted to be easily readable.\n",
    "    \n",
    "    THINK STEP BY STEP\n",
    "    \n",
    "    Answer the following question using the provided context.\n",
    "    ### Question: {question} ###\n",
    "    ### Context: {context} ###     \n",
    "    ### Helpful Answer with Sources:\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "    \n",
    "    # Create the chain\n",
    "    self.chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | self.llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    logger.info(\"RAG chain setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Answering Questions\n",
    "\n",
    "Time to shine! The robot takes your question, processes it, and gives you an answer. If something goes wrong, it politely lets you know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(self, question: str) -> str:\n",
    "    \"\"\"\n",
    "    Answer a question using the RAG chain\n",
    "    \n",
    "    Args:\n",
    "        question: The question to answer\n",
    "        \n",
    "    Returns:\n",
    "        The answer to the question\n",
    "    \"\"\"\n",
    "    if not self.chain:\n",
    "        self.setup_chain()\n",
    "    \n",
    "    logger.info(f\"Answering question: {question}\")\n",
    "    try:\n",
    "        answer = self.chain.invoke(question)\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error answering question: {e}\")\n",
    "        return f\"Error processing your question: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A Window to the World: Gradio Interface\n",
    "\n",
    "Let‚Äôs make our robot user-friendly with a web interface.\n",
    "\n",
    "### üåê Why Gradio?\n",
    "It‚Äôs like building an app with Lego blocks: easy, fast, and you can use it from your phone or computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gradio_interface(rag_system: RAGSystem) -> gr.Interface:\n",
    "    \"\"\"\n",
    "    Create a Gradio interface for the RAG system\n",
    "    \n",
    "    Args:\n",
    "        rag_system: The RAG system to use\n",
    "        \n",
    "    Returns:\n",
    "        A Gradio interface\n",
    "    \"\"\"\n",
    "    def get_answer(question: str) -> str:\n",
    "        \"\"\"Wrapper function for the Gradio interface\"\"\"\n",
    "        return rag_system.answer_question(question)\n",
    "    \n",
    "    # Gradio interface configuration\n",
    "    interface = gr.Interface(\n",
    "        fn=get_answer,\n",
    "        inputs=gr.Textbox(\n",
    "            placeholder=\"Ask a question about immigration...\",\n",
    "            label=\"Your Question\"\n",
    "        ),\n",
    "        outputs=gr.Markdown(label=\"Answer\"),\n",
    "        title=\"Document Intelligence System with LLM\",\n",
    "        description=\"Ask any question about immigration based on the loaded documents\",\n",
    "        theme=gr.themes.Soft(),\n",
    "        allow_flagging=\"never\",\n",
    "        examples=[\n",
    "            \"How many immigrants arrive each year?\",\n",
    "            \"What are the main countries of origin?\",\n",
    "            \"What economic impact does immigration have?\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Let‚Äôs Get It Running!\n",
    "\n",
    "The ‚Äústart button‚Äù checks everything, tests a question, and opens the interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    \"\"\"Main function to run the RAG system\"\"\"\n",
    "    try:\n",
    "        # Display available models\n",
    "        print(\"\\n==== CHECKING OLLAMA MODELS ====\")\n",
    "        try:\n",
    "            import requests\n",
    "            response = requests.get(\"http://localhost:11434/api/tags\")\n",
    "            print(\"Available Ollama models:\")\n",
    "            if response.status_code == 200:\n",
    "                for model in response.json().get(\"models\", []):\n",
    "                    print(f\"- {model['name']}\")\n",
    "            else:\n",
    "                print(f\"Error checking Ollama models: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to Ollama: {e}\")\n",
    "        \n",
    "        print(f\"\\nUsing LLM model: {LLM_MODEL}\")\n",
    "        print(f\"Using embedding model: {EMBEDDING_MODEL}\")\n",
    "        print(\"Make sure these models are available with 'ollama pull' commands.\")\n",
    "        \n",
    "        # Create and initialize the RAG system\n",
    "        rag_system = RAGSystem(pdf_urls=PDF_URLS)\n",
    "        \n",
    "        # Load documents and create vectorstore\n",
    "        rag_system.load_documents()\n",
    "        rag_system.create_vectorstore()\n",
    "        \n",
    "        # Test with a control question\n",
    "        logger.info(\"Testing with a control question...\")\n",
    "        test_answer = rag_system.answer_question(\"How many immigrants arrive each year?\")\n",
    "        logger.info(f\"Control answer received (length: {len(test_answer)})\")\n",
    "        \n",
    "        # Create and launch Gradio interface\n",
    "        logger.info(\"Launching Gradio interface...\")\n",
    "        interface = create_gradio_interface(rag_system)\n",
    "        interface.launch(share=False)  # Set share=True to create a public link\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred in the main function: {e}\")\n",
    "        print(f\"\\n\\nERROR: {str(e)}\\n\\n\")\n",
    "        print(\"\\nTROUBLESHOOTING TIPS:\")\n",
    "        print(\"1. Make sure Ollama is running: 'ollama serve'\")\n",
    "        print(f\"2. Make sure you have pulled the required models:\")\n",
    "        print(f\"   - ollama pull {LLM_MODEL}\")\n",
    "        print(f\"   - ollama pull {EMBEDDING_MODEL}\")\n",
    "        print(\"3. If you're still having dimension issues, try using a different embedding model by changing EMBEDDING_MODEL\")\n",
    "        print(\"4. Check that you have the required Python packages installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It Together\n",
    "\n",
    "Time to assemble our robot and make it run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the methods to the RAGSystem class\n",
    "RAGSystem.load_documents = load_documents\n",
    "RAGSystem.create_vectorstore = create_vectorstore\n",
    "RAGSystem.setup_chain = setup_chain\n",
    "RAGSystem.answer_question = answer_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== CHECKING OLLAMA MODELS ====\n",
      "Available Ollama models:\n",
      "- all-minilm:latest\n",
      "\n",
      "Using LLM model: llama3.2:1b\n",
      "Using embedding model: all-minilm\n",
      "Make sure these models are available with 'ollama pull' commands.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danielle\\AppData\\Local\\Temp\\ipykernel_4808\\1044174799.py:23: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  rag_system = RAGSystem(pdf_urls=PDF_URLS)\n",
      "2025-03-13 15:04:55,675 - __main__ - INFO - Initialized RAG system with 2 PDFs\n",
      "2025-03-13 15:04:55,676 - __main__ - INFO - Loading and processing PDFs...\n",
      "2025-03-13 15:05:03,675 - __main__ - INFO - Loaded 5 pages from https://www.ine.es/daco/daco42/ecp/ecp0123.pdf\n",
      "2025-03-13 15:05:08,577 - __main__ - INFO - Loaded 37 pages from https://fundacionalternativas.org/wp-content/uploads/2023/10/PERSONAS_MIGRANTES_v02.pdf\n",
      "2025-03-13 15:05:08,582 - __main__ - INFO - Created 165 document chunks\n",
      "2025-03-13 15:05:08,584 - __main__ - INFO - Creating new vectorstore...\n",
      "2025-03-13 15:05:08,585 - __main__ - INFO - Using temporary directory for initial database creation: C:\\Users\\Danielle\\AppData\\Local\\Temp\\tmpclbs9z1u\n",
      "2025-03-13 15:05:08,586 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-03-13 15:05:26,074 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:05:26,285 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-03-13 15:05:28,220 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "C:\\Users\\Danielle\\AppData\\Local\\Temp\\ipykernel_4808\\1117243408.py:37: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  self.vectorstore.persist()\n",
      "2025-03-13 15:05:28,422 - __main__ - INFO - Vectorstore created successfully with 165 documents\n",
      "2025-03-13 15:05:28,423 - __main__ - INFO - Testing with a control question...\n",
      "2025-03-13 15:05:28,426 - __main__ - INFO - RAG chain setup complete\n",
      "2025-03-13 15:05:28,427 - __main__ - INFO - Answering question: How many immigrants arrive each year?\n",
      "2025-03-13 15:05:28,584 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:05:28,627 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 404 Not Found\"\n",
      "2025-03-13 15:05:28,627 - __main__ - ERROR - Error answering question: model \"llama3.2:1b\" not found, try pulling it first (status code: 404)\n",
      "2025-03-13 15:05:28,628 - __main__ - INFO - Control answer received (length: 102)\n",
      "2025-03-13 15:05:28,629 - __main__ - INFO - Launching Gradio interface...\n",
      "C:\\Users\\Danielle\\AppData\\Roaming\\Python\\Python313\\site-packages\\gradio\\interface.py:403: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 15:05:29,602 - httpx - INFO - HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:05:29,810 - httpx - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 15:05:29,895 - httpx - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:06:01,597 - __main__ - INFO - Answering question: Where did the immigrants come from?\n",
      "2025-03-13 15:06:01,986 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:06:02,029 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 404 Not Found\"\n",
      "2025-03-13 15:06:02,038 - __main__ - ERROR - Error answering question: model \"llama3.2:1b\" not found, try pulling it first (status code: 404)\n",
      "2025-03-13 15:17:35,808 - __main__ - INFO - Answering question: Where did the immigrants come from?\n",
      "2025-03-13 15:17:37,774 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-03-13 15:17:40,117 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I understand that you are seeking information on the origin of immigrants in Spain. Based on the context provided, it appears that the question is asking about the historical and demographic trends surrounding immigration to Spain.\n",
      "\n",
      "According to various sources, including academic papers and reports from international organizations, the majority of immigrants to Spain have come from countries such as Morocco, Algeria, and Tunisia. These countries have historically had significant economic and social ties with Spain, leading to a large influx of migrants seeking better opportunities.\n",
      "\n",
      "One notable source is the work of Spanish sociologist C√©sar Mu√±oz Fern√°ndez, who has studied the topic of immigration in Spain. In his book \"La integraci√≥n de los inmigrantes en Espa√±a\" (The Integration of Immigrants in Spain), he argues that the majority of immigrants to Spain have come from countries with strong economic ties to Spain.\n",
      "\n",
      "Another source is the report by the European Union's Agency for Fundamental Rights, which notes that many immigrants to Spain are seeking better economic opportunities and fleeing conflict or persecution in their home countries. The report also highlights the importance of addressing the root causes of migration, such as poverty and inequality.\n",
      "\n",
      "In terms of specific statistics, a 2020 report by the Spanish National Institute of Statistics (INE) found that the majority of foreign-born residents in Spain are from Morocco (34.6%), followed by Algeria (14.1%) and Tunisia (10.3%).\n",
      "\n",
      "Overall, it appears that the origin of immigrants to Spain is complex and multifaceted, with various factors contributing to the country's immigration patterns.\n",
      "\n",
      "Sources:\n",
      "\n",
      "* Mu√±oz Fern√°ndez, C. (2017). La integraci√≥n de los inmigrantes en Espa√±a. Madrid: Editorial Universitaria.\n",
      "* European Union Agency for Fundamental Rights. (2020). Migration and integration in Europe: A review of the literature. Brussels: Agency.\n",
      "* INE. (2020). Foreign-born population in Spain, 2019. Madrid: Instituto Nacional de Estad√≠stica.\n",
      "\n",
      "Note: The sources provided are academic papers and reports from international organizations, which provide a more comprehensive understanding of the topic."
     ]
    }
   ],
   "source": [
    "# Run the system\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "else:\n",
    "    # If running in a notebook\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #2d333b; padding: 5px; border-radius: 4px; margin-bottom: 10px;\">\n",
    "  <h2 style=\"color: #58a6ff; margin: 10px;\">7. What Happens When You Ask a Question?</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #22272e; padding: 15px; border-radius: 8px; border-left: 4px solid #d2a8ff; margin-bottom: 20px;\">\n",
    "  <p style=\"color: #adbac7;\">Let's see exactly what happens behind the scenes when you ask your RAG system a question. This is where all the pieces come together!</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #1c2128; border-radius: 8px; overflow: hidden; margin: 20px 0; border: 1px solid #444c56;\">\n",
    "  <!-- Step 1 -->\n",
    "  <div style=\"display: flex; padding: 15px; border-bottom: 1px solid #444c56; background-color: #22272e;\">\n",
    "    <div style=\"width: 60px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center;\">\n",
    "        <span style=\"color: #d2a8ff; font-weight: bold;\">1</span>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; padding-left: 10px;\">\n",
    "      <p style=\"color: #d2a8ff; font-weight: bold; margin: 0;\">You Ask</p>\n",
    "      <p style=\"color: #adbac7; margin-top: 5px;\">\"How many immigrants arrive each year?\"</p>\n",
    "    </div>\n",
    "    <div style=\"width: 50px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <span style=\"font-size: 1.5em;\">‚ùì</span>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <!-- Step 2 -->\n",
    "  <div style=\"display: flex; padding: 15px; border-bottom: 1px solid #444c56; background-color: #1c2128;\">\n",
    "    <div style=\"width: 60px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center;\">\n",
    "        <span style=\"color: #d2a8ff; font-weight: bold;\">2</span>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; padding-left: 10px;\">\n",
    "      <p style=\"color: #d2a8ff; font-weight: bold; margin: 0;\">Magic Fingerprint</p>\n",
    "      <p style=\"color: #adbac7; margin-top: 5px;\">Your question becomes a vector: [0.21, -0.48, 0.73, ...]</p>\n",
    "    </div>\n",
    "    <div style=\"width: 50px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <span style=\"font-size: 1.5em;\">üßÆ</span>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <!-- Step 3 -->\n",
    "  <div style=\"display: flex; padding: 15px; border-bottom: 1px solid #444c56; background-color: #22272e;\">\n",
    "    <div style=\"width: 60px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center;\">\n",
    "        <span style=\"color: #d2a8ff; font-weight: bold;\">3</span>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; padding-left: 10px;\">\n",
    "      <p style=\"color: #d2a8ff; font-weight: bold; margin: 0;\">Finds Clues</p>\n",
    "      <p style=\"color: #adbac7; margin-top: 5px;\">System finds the 5 most similar chunks from your documents</p>\n",
    "    </div>\n",
    "    <div style=\"width: 50px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <span style=\"font-size: 1.5em;\">üîç</span>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <!-- Step 4 -->\n",
    "  <div style=\"display: flex; padding: 15px; border-bottom: 1px solid #444c56; background-color: #1c2128;\">\n",
    "    <div style=\"width: 60px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center;\">\n",
    "        <span style=\"color: #d2a8ff; font-weight: bold;\">4</span>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; padding-left: 10px;\">\n",
    "      <p style=\"color: #d2a8ff; font-weight: bold; margin: 0;\">Puts It Together</p>\n",
    "      <p style=\"color: #adbac7; margin-top: 5px;\">Combines those chunks into a single \"context\" document</p>\n",
    "    </div>\n",
    "    <div style=\"width: 50px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <span style=\"font-size: 1.5em;\">üìÑ</span>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <!-- Step 5 -->\n",
    "  <div style=\"display: flex; padding: 15px; border-bottom: 1px solid #444c56; background-color: #22272e;\">\n",
    "    <div style=\"width: 60px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center;\">\n",
    "        <span style=\"color: #d2a8ff; font-weight: bold;\">5</span>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; padding-left: 10px;\">\n",
    "      <p style=\"color: #d2a8ff; font-weight: bold; margin: 0;\">Talks to the AI</p>\n",
    "      <p style=\"color: #adbac7; margin-top: 5px;\">Sends your question + context + instructions to the LLM</p>\n",
    "    </div>\n",
    "    <div style=\"width: 50px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <span style=\"font-size: 1.5em;\">üß†</span>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <!-- Step 6 -->\n",
    "  <div style=\"display: flex; padding: 15px; border-bottom: 1px solid #444c56; background-color: #1c2128;\">\n",
    "    <div style=\"width: 60px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center;\">\n",
    "        <span style=\"color: #d2a8ff; font-weight: bold;\">6</span>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; padding-left: 10px;\">\n",
    "      <p style=\"color: #d2a8ff; font-weight: bold; margin: 0;\">Answer Ready</p>\n",
    "      <p style=\"color: #adbac7; margin-top: 5px;\">The AI writes a clear, helpful response based on the context</p>\n",
    "    </div>\n",
    "    <div style=\"width: 50px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <span style=\"font-size: 1.5em;\">‚úçÔ∏è</span>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <!-- Step 7 -->\n",
    "  <div style=\"display: flex; padding: 15px; background-color: #22272e;\">\n",
    "    <div style=\"width: 60px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <div style=\"background-color: #2d333b; width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center;\">\n",
    "        <span style=\"color: #d2a8ff; font-weight: bold;\">7</span>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; padding-left: 10px;\">\n",
    "      <p style=\"color: #d2a8ff; font-weight: bold; margin: 0;\">Shows You</p>\n",
    "      <p style=\"color: #adbac7; margin-top: 5px;\">You see the formatted answer on your screen</p>\n",
    "    </div>\n",
    "    <div style=\"width: 50px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <span style=\"font-size: 1.5em;\">üí°</span>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #1c2128; padding: 20px; border-radius: 8px; margin: 20px 0; border: 1px solid #444c56;\">\n",
    "  <h3 style=\"color: #7ee787; margin-top: 0;\">Why It's Awesome</h3>\n",
    "  \n",
    "  <div style=\"display: flex; margin-bottom: 15px;\">\n",
    "    <div style=\"width: 30px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <span style=\"color: #7ee787;\">‚úÖ</span>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; padding-left: 10px;\">\n",
    "      <p style=\"color: #adbac7; margin: 0;\"><strong>Spot-On</strong>: Uses your actual PDF content, not guesses or outdated training data</p>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <div style=\"display: flex; margin-bottom: 15px;\">\n",
    "    <div style=\"width: 30px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <span style=\"color: #7ee787;\">‚úÖ</span>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; padding-left: 10px;\">\n",
    "      <p style=\"color: #adbac7; margin: 0;\"><strong>Fresh</strong>: Answers with the latest information from your documents</p>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <div style=\"display: flex;\">\n",
    "    <div style=\"width: 30px; display: flex; align-items: center; justify-content: center;\">\n",
    "      <span style=\"color: #7ee787;\">‚úÖ</span>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; padding-left: 10px;\">\n",
    "      <p style=\"color: #adbac7; margin: 0;\"><strong>Clear</strong>: Tells you exactly where it found the information</p>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #22272e; border-radius: 8px; overflow: hidden; margin: 20px 0; border: 1px solid #444c56;\">\n",
    "  <div style=\"padding: 15px; background-color: #2d333b; border-bottom: 1px solid #444c56;\">\n",
    "    <h3 style=\"color: #58a6ff; margin: 0;\">Sample Answer</h3>\n",
    "  </div>\n",
    "  \n",
    "  <div style=\"padding: 20px; background-color: #1c2128; font-family: system-ui, -apple-system, sans-serif;\">\n",
    "    <p style=\"color: #adbac7; margin-top: 0;\">Hi there! You asked how many immigrants arrive each year.</p>\n",
    "    <p style=\"color: #adbac7;\">According to the documents, about 515,000 people came to Spain in 2021, mostly from Latin America and Morocco.</p>\n",
    "    <p style=\"color: #d2a8ff; font-weight: bold; margin-bottom: 5px;\">Sources:</p>\n",
    "    <ul style=\"color: #adbac7; margin-top: 0;\">\n",
    "      <li>INE Report (2021), page 15</li>\n",
    "      <li>Personas Migrantes (2023), section 2.3</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #2d333b; border-left: 4px solid #d2a8ff; padding: 15px; border-radius: 5px; margin-top: 20px;\">\n",
    "  <p style=\"color: #adbac7; margin: 0;\"><strong style=\"color: #adbac7;\">üí° Key Insight:</strong> The quality of your answer depends on two critical factors: (1) how well your system finds the relevant chunks, and (2) how well your prompt instructs the LLM to use those chunks. Both retrieval quality and prompt engineering matter!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Wrapping Up: What You've Learned\n",
    "\n",
    "<div style=\"background-color: #22272e; padding: 15px; border-radius: 8px; border-left: 4px solid #58a6ff; margin-bottom: 20px;\">\n",
    "  <p style=\"color: #adbac7;\">Great job! You've built a complete RAG system that can answer questions based on your documents. Let's recap what you've accomplished.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #1c2128; border-radius: 8px; padding: 20px; margin: 20px 0; border: 1px solid #444c56;\">\n",
    "  <h3 style=\"color: #58a6ff; margin-top: 0;\">üèÜ Your New Skills</h3>\n",
    "  \n",
    "  <ul style=\"color: #adbac7; list-style-type: none; padding-left: 0;\">\n",
    "    <li style=\"margin-bottom: 10px; display: flex; align-items: center;\">\n",
    "      <span style=\"color: #58a6ff; margin-right: 10px;\">‚úì</span>\n",
    "      <span><strong>Document Processing</strong> - Chunking PDFs into searchable pieces</span>\n",
    "    </li>\n",
    "    <li style=\"margin-bottom: 10px; display: flex; align-items: center;\">\n",
    "      <span style=\"color: #58a6ff; margin-right: 10px;\">‚úì</span>\n",
    "      <span><strong>Vector Storage</strong> - Turning text into searchable vectors</span>\n",
    "    </li>\n",
    "    <li style=\"margin-bottom: 10px; display: flex; align-items: center;\">\n",
    "      <span style=\"color: #58a6ff; margin-right: 10px;\">‚úì</span>\n",
    "      <span><strong>Semantic Search</strong> - Finding information by meaning, not just keywords</span>\n",
    "    </li>\n",
    "    <li style=\"margin-bottom: 10px; display: flex; align-items: center;\">\n",
    "      <span style=\"color: #58a6ff; margin-right: 10px;\">‚úì</span>\n",
    "      <span><strong>LLM Integration</strong> - Getting AI to generate helpful answers</span>\n",
    "    </li>\n",
    "    <li style=\"display: flex; align-items: center;\">\n",
    "      <span style=\"color: #58a6ff; margin-right: 10px;\">‚úì</span>\n",
    "      <span><strong>Web Interface</strong> - Making your AI accessible through Gradio</span>\n",
    "    </li>\n",
    "  </ul>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #1c2128; border-radius: 8px; padding: 20px; margin: 20px 0; border: 1px solid #444c56;\">\n",
    "  <h3 style=\"color: #f0883e; margin-top: 0;\">üöÄ Next Steps & Ideas</h3>\n",
    "  \n",
    "  <p style=\"color: #adbac7;\">Here are some cool ways to expand your project:</p>\n",
    "  <ul style=\"color: #adbac7; padding-left: 20px;\">\n",
    "    <li>Process different file types (Word docs, webpages, etc.)</li>\n",
    "    <li>Add a file upload feature to your interface</li>\n",
    "    <li>Experiment with different models and parameters</li>\n",
    "    <li>Enable conversation history for follow-up questions</li>\n",
    "  </ul>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #1c2128; border-radius: 8px; padding: 20px; margin: 20px 0; border: 1px solid #444c56;\">\n",
    "  <h3 style=\"color: #7ee787; margin-top: 0;\">üîó Share Your Projects!</h3>\n",
    "  \n",
    "  <p style=\"color: #adbac7;\">We'd love to see what you build with these skills!</p>\n",
    "  \n",
    "  <div style=\"margin-top: 15px;\">\n",
    "    <p style=\"color: #adbac7; margin-bottom: 5px;\"><strong>Share your experiments:</strong></p>\n",
    "    <ul style=\"color: #adbac7; padding-left: 20px;\">\n",
    "      <li>Tag us on GitHub when you publish your repo</li>\n",
    "      <li>Share screenshots or demos on social media with <strong>#maiaph</strong></li>\n",
    "      <li>Our team will review and provide feedback on your work</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "  \n",
    "  <p style=\"color: #adbac7; margin-top: 15px;\">The best projects will be featured on our website and social media!</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center; background-color: #22272e; padding: 20px; border-radius: 10px; margin-top: 30px;\">\n",
    "  <img src=\"https://www.maia.ph/logomaia.svg\" width=\"100\" alt=\"MAIA Academy Logo\" style=\"margin-bottom: 15px;\"/>\n",
    "  <h3 style=\"color: #adbac7; margin-bottom: 10px;\">Keep Building Amazing AI Projects!</h3>\n",
    "  <p style=\"color: #adbac7; margin-bottom: 5px;\">Follow us for more tutorials and resources:</p>\n",
    "  <p style=\"color: #79c0ff;\">www.maia.ph | @maiaedtech | info@maia.ph</p>\n",
    "  <p style=\"color: #7ee787; font-weight: bold; margin-top: 15px;\">#maiaph</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #1c2128; border-radius: 8px; padding: 15px; margin: 20px 0; border: 1px dashed #444c56;\">\n",
    "  <h3 style=\"color: #d2a8ff; margin-top: 0;\">P.S.</h3>\n",
    "  <p style=\"color: #adbac7;\">If you've made it this far programming with a light background ‚Äî the warning about being a psychopath was just a joke. We love you regardless of your IDE theme preferences!</p>\n",
    "  <p style=\"color: #adbac7;\">However, if you've been coding along in dark mode... well, we meant every word. You're one of the good ones, and your retinas thank you. üëÄ</p>\n",
    "  <p style=\"color: #adbac7; margin-bottom: 0;\">Either way, thanks for joining us on this RAG adventure. We can't wait to see what you build!</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
